{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"Bag-o-words\" Approach\n",
    "\n",
    "Creates a representation of the document, usually with a stop list.\n",
    "\n",
    "A stop list is a list of words like \"the\", \"and\", or \"but\" that punctuate a document.\n",
    "\n",
    "Possible methods:\n",
    "- Term frequency (raw number of times a word appears)\n",
    "- Normalized term frequency (percentage of times a word appears)\n",
    "- Inverse document frequency (what percentage of documents does this word occur in?)\n",
    "\n",
    "The combination of these methods is called TF-IDF.\n",
    "\n",
    "TF-IDF gives a list of words that acts as a *frequency vector*, which we can compare with a Perceptron or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import log, sqrt\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = datasets.fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['target', 'filenames', 'target_names', 'DESCR', 'data'])\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "[7 4 4 ..., 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "print(doc.keys())\n",
    "print(doc.target_names)\n",
    "print(doc.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware \n",
      "\n",
      " From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc.target_names[doc.target[1]], \"\\n\\n\", doc.data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic algorithm:\n",
    "- Manipulate text\n",
    "- Get dictionary of words and their idf values\n",
    "- Compare with cos(theta), return how similar they are in terms of the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocumentAnalyzer:\n",
    "    # Constructor manipulates documents into an easier-to-analyze format\n",
    "    def __init__(self, documents):\n",
    "        self.ALPHANUMERIC = \"a b c d e f g h i j k l m n o p q r s t u v w x y z 0 1 2 3 4 5 6 7 8 9\".split(' ')\n",
    "        self.doclist = []\n",
    "        self.termlist = {}\n",
    "        for doc in documents:\n",
    "            self.doclist.append(self.fix_text(doc))            \n",
    "    \n",
    "    # Splits a list into its constituent parts, removing all punctuation and numbers\n",
    "    # Perhaps unfortunately, this also splits email addresses.\n",
    "    def fix_text(self, text):\n",
    "        new_text = \"\"\n",
    "        for char in text.lower():\n",
    "            if char in self.ALPHANUMERIC:\n",
    "                new_text += char\n",
    "            else:\n",
    "                new_text += ' '\n",
    "        return [x for x in new_text.split() if not x.isdigit() and not x in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # Gets the term frequency of a word in a document\n",
    "    # Uses Wikipedia's \"log normalization\" weighting scheme\n",
    "    def _tf(self, doc_id, w):\n",
    "        f = 0\n",
    "        for word in self.doclist[doc_id]:\n",
    "            if w == word:\n",
    "                f += 1\n",
    "        return log(1 + f)\n",
    "\n",
    "    # Gets the inverse document frequency of a word in a collection of documents\n",
    "    # Uses Wikipedia's \"inverse frequency smooth\" weighting scheme\n",
    "    def _idf(self, t):\n",
    "        n = 0\n",
    "        for doc in self.doclist:\n",
    "            if t in doc:\n",
    "                n += 1\n",
    "        # n should always be greater than 0, but just in case . . .\n",
    "        if n > 0:\n",
    "            return log(1 + len(self.doclist) / n)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Gets the TF-IDF value of a word\n",
    "    def _tf_idf(self, doc_id, term):\n",
    "        return self._tf(doc_id, term) * self._idf(term)\n",
    "    \n",
    "    # Returns cos(theta) for two documents with the given ids\n",
    "    def compare(self, a_id, b_id):\n",
    "        # Lazy-load TF-IDF vectors for a and b\n",
    "        if not a_id in self.termlist.keys():\n",
    "            self.termlist[a_id] = {}\n",
    "            for word in self.doclist[a_id]:\n",
    "                self.termlist[a_id][word] = self._tf_idf(a_id, word)\n",
    "        if b_id not in self.termlist.keys():\n",
    "            self.termlist[b_id] = {}\n",
    "            for word in self.doclist[b_id]:\n",
    "                self.termlist[b_id][word] = self._tf_idf(b_id, word)\n",
    "        \n",
    "        # The dot product is defined as the sum of the elements in an elementwise-product of a and b.\n",
    "        # It is also defined as the product of the magnitudes of a and b and cos(theta) where theta \n",
    "        # is the angle between a and b. So cos(theta) is the dot product dived by the product of the\n",
    "        # magnitudes of a and b.\n",
    "        dot_product = self.dot(self.termlist[a_id], self.termlist[b_id])\n",
    "        a_mag, b_mag = self.magnitude(self.termlist[a_id]), self.magnitude(self.termlist[b_id])\n",
    "        try:\n",
    "            cos = dot_product / (a_mag * b_mag)\n",
    "        except:\n",
    "            cos = 0\n",
    "            \n",
    "        return cos\n",
    "    \n",
    "    # Takes two dictionaries of TF-IDF values and returns dot product\n",
    "    def dot(self, a, b):\n",
    "        total = 0\n",
    "        for key in a.keys():\n",
    "            if key in b.keys():\n",
    "                total += (a[key] * b[key])\n",
    "        return total\n",
    "    \n",
    "    # Takes a dictionary of TF-IDF values and returns magnitude\n",
    "    def magnitude(self, v):\n",
    "        total = 0\n",
    "        for key in v.keys():\n",
    "            total += (v[key] * v[key])\n",
    "        return sqrt(total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "da = DocumentAnalyzer(doc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03349717081922913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.compare(0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
